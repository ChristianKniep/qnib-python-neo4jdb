#! /usr/bin/env python
# -*- coding: utf-8 -*-

import time
import math
from datetime import datetime, timedelta
from pytz import timezone
from pprint import pprint
# extra libs
from neo4jrestclient.client import GraphDatabase, Node
from neo4jrestclient.query import QuerySequence
from requests.exceptions import ConnectionError
from qnib_graphdb import GraphDB
from ClusterShell.NodeSet import NodeSet


class XmitPortCnt(object):
    """ Object to hold an outgoing port counter for a given path element
    """
    def __init__(self, **kwargs):
        """ Intake of all elements of the CYPHER query
        """
        self._end_node = False
        if 'end_node' in kwargs.keys():
            self._end_node = kwargs['end_node']
        self._hca = kwargs['hca']
        self._sw = kwargs['sw']
        self._sw_port = kwargs['sw_port']
        self._con = kwargs['con']

    def __str__(self):
        """ human representation
        """
        txt = []
        txt.append("RouteTo:'%(name)s'" % self._hca)
        txt.append("Hop:%(name)s" % self._con)
        return "|".join(txt)

    def get_xmit_metric(self, prefix="ib"):
        """ Generates carbon-metric, target name and alias to put into dashboard
        :return: (target, alias, metric)
        """
        if self._end_node:
            metric = "%s.%s.port%s.rcv_data" % (prefix, self._sw_port['guid'], self._sw_port['port_int'])
        else:
            metric = "%s.%s.port%s.xmit_data" % (prefix, self._sw_port['guid'], self._sw_port['port_int'])
        return (self._hca['name'].split("_")[0], self._con['name'], metric)


class SlurmJob(object):
    """ Holds one Job
    """
    def __init__(self, job):
        """
        :param job: Job-dict
        """
        self.job = job
        self.nodes = []
        self._routes = {}
        self._endnodes = {}

    def add_node(self, hca):
        """
        :param hca: node-dict
        """
        self.nodes.append(hca)

    def __str__(self):
        """
        :return: human readable representation
        """
        txt = []
        txt.append("JobID:%(id)s - %(state)s (%(command)s)" % self.job)
        return "|".join(txt)

    def create_node_regex(self):
        """
        :return: regex matching all nodes
        """
        names = []
        for node in self.nodes:
            names.append(node['name'])
        return "(%s)" % "|".join(names)

    def add_route(self, xp):
        """
        :param route: tupel from XmitPortCnt.get_xmit_metric()
        """
        target, alias, metric = xp.get_xmit_metric()
        if target not in self._routes.keys():
            self._routes[target] = []
        if xp._end_node:
            if target not in self._endnodes.keys():
                self._endnodes[target] = []
            self._endnodes[target].append((alias, metric))
        else:
            self._routes[target].append((alias, metric))

    def get_target_metrics(self):
        """
        :return: [(target, [carbon_metrics, ...]),]
        """
        ret = []
        for target, vals in self._routes.items():
            for val in vals:
                #metric = "alias(%s, '%s')" % (val[1], val[0])
                ret.append((target, val[1]))
        return ret

    def render(self):
        """
        :return: dict to render individual SLURM dashboard

        Needs: {
         'jobid': jobid,                        # simple jobid
         'jobname': name,                       # the name of the job
         'jobcmd':                              # Command during submission
         'endnodes': [(alias, metric),...],     # End node xmit_data metrics
         'routes': {
                target: [(alias, metric),...],
            },
        }
        """
        endnodes = []
        for node, vals in self._endnodes.items():
            for _, key in vals:
                endnodes.append((node, key))

        dt_start = datetime.strptime(self.job['started'],"%Y-%m-%dT%H:%M:%S")
        dt_start = dt_start.replace(tzinfo=timezone('Europe/Oslo'))
        dt_utc_start = dt_start - timedelta(hours=2) - timedelta(minutes=5)
        utc_start = dt_utc_start.strftime("%Y-%m-%dT%H:%M:%S.000Z")
        ret = {
            'jobid': self.job['id'],
            'jobname': self.job['name'],
            'user': self.job['user'],
            'start': self.job['started'],
            'utc_start': utc_start,
            'state': self.job['state'],
            'end': "",
            'utc_end': "now",
            'jobcmd': self.job['command'],
            'endnodes': endnodes,
            'routes': self._routes,
        }
        if 'end' in self.job.keys():
            dt_end = datetime.strptime(self.job['end'],"%Y-%m-%dT%H:%M:%S")
            dt_end = dt_end.replace(tzinfo=timezone('Europe/Oslo'))
            dt_utc_end = dt_end - timedelta(hours=2) + timedelta(minutes=5)
            ret['end'] = self.job['end']
            ret['utc_end'] = dt_utc_end.strftime("%Y-%m-%dT%H:%M:%S.000Z")
        return ret

    def render_running(self):
        """
        :return: dict to render within running_jobs list
        #  jobid, jobname, user, start, nodes
        """
        jobid = self.job['id']
        jobname = self.job['name']
        user = self.job['user']
        start = self.job['started']
        state = self.job['state']
        dt_start = datetime.strptime(self.job['started'],"%Y-%m-%dT%H:%M:%S")
        duration = int(self.diff_time(dt_start, datetime.now()))
        nodes = ",".join(self._endnodes.keys())
        return  jobid, jobname, user, start, state, nodes, duration

    @staticmethod
    def diff_time(start, end):
        return math.floor(((end-start).seconds) / 60)

    def render_finished(self):
        """
        :return: dict to render within running_finished list
        """
        jobid = self.job['id']
        jobname = self.job['name']
        user = self.job['user']
        start = self.job['started']
        end = self.job['end']
        state = self.job['state']
        dt_start = datetime.strptime(self.job['started'],"%Y-%m-%dT%H:%M:%S")
        dt_end = datetime.strptime(self.job['end'],"%Y-%m-%dT%H:%M:%S")
        nodes = ",".join(self._endnodes.keys())
        duration = int(self.diff_time(dt_start, dt_end))
        ec = "?"
        return  jobid, jobname, user, start, end, state, nodes, duration, ec



class N4jDB(GraphDB):
    def __init__(self, cfg):
        super(N4jDB, self).__init__(cfg)

    def con_gdb(self):
        """ connect to neo4j
        """
        try:
            url = "http://%(--neo4j-host)s:7474" % self._cfg
        except:
            url = "http://%(--host)s:7474" % self._cfg
        try:
            self._gdb = GraphDatabase(url)
        except ConnectionError:
            time.sleep(3)
            self.con_gdb()

    def create_node(self, node):
        """
        :param node: dict with node information

        """
        # FIXME: This is not quite right for now, since the lid is provided by the node, even though it
        # should be part of the port information, since a node could have multiple ports, hence
        # multiple lids.
        query = "MERGE (n:%(Type)s {guid:'%(Guid)s', name:'%(Name)s', lids:['%(Lid)s']}) " % node
        port_cnt = int(node['Guid'][2:], 16)
        for pnr in range(1, node['Ports'] + 1):
            port_cnt += 1
            if node['Type'] == 'SW':
                pguid = node['Guid']
            else:
                pguid = "0x%x" % port_cnt
            query += " MERGE (n)<-[:PART_OF]-(p%s:PORT {guid:'%s', port_int:'%s', lid:'%s'})" % (pnr, pguid, pnr, node['Lid'])
        self._gdb.query(query)
        msg = "Made sure node with guid '%(Guid)s' is in graph" % node
        self._cfg._logger.debug(msg)

    def merge_link(self, link, link_type, seen):
        if link_type in ("ASICLinkList", "ASICList"):
            self.merge_sw_link(link, seen)
        elif link_type in ("HCALinkList", "HCAList"):
            # a link originating from a HCA can only link to a switch...
            self.merge_hca_link(link, seen)

    def mark_old_connections(self, seen):
        """
        """
        query = "MATCH (c:Connections {state:'LATEST'}) WHERE NOT c.seen='%s'" % seen
        query += " SET c.state='OUTDATED'"
        self._gdb.query(query)

    def merge_hca_link(self, link, seen):
        """ !! Origin of this link is a HCA
        Since they have to be connected to a switch, it's fair to assume that
        the destination is going to be a switch
        """
        link['seen'] = seen
        name = "%s[%s]->SW%s[%s]" % (
            link['src_name'].split("_")[0], link['src_port'],
            link['dst_guid'][-3:], link['dst_port'],
        )
        query = "MATCH (src)<-[:PART_OF]-(sp:PORT {guid:'%(src_guid)s', port_int:'%(src_port)s'})," % link
        query += " (dest)<-[:PART_OF]-(dp:PORT {guid:'%(dst_guid)s', port_int:'%(dst_port)s'})" % link
        query += " MERGE (sp)-[:CON]->(c0:Connection)-[:CON]->(dp)"
        query += "  ON MATCH SET c0.seen='%(seen)s'" % link
        query += "  ON CREATE SET c0.created='%(seen)s', c0.seen='%(seen)s', c0.state='LATEST'," % link
        query += "                c0.name='%s'" % name
        query += " MERGE (src)-[:LINKED]->(dest)"
        self._cfg._logger.debug(query)
        self._gdb.query(query, params=link)

    def merge_sw_link(self, link, seen):
        """ !! Origin of this link is a SW
        -> Depending on what the destination is, we have to handle it differently
        """
        # TODO: Not optimal!
        link['seen'] = seen
        ## If it's a switch
        name = "SW%s[%s]->SW%s[%s]" % (
            link['src_guid'][-3:], link['src_port'],
            link['dst_guid'][-3:], link['dst_port'],
        )
        query = "MATCH (src)<-[:PART_OF]-(sp:PORT {guid:'%(src_guid)s', port_int:'%(src_port)s'})," % link
        query += " (dest:SW {guid:'%(dst_guid)s'})<-[:PART_OF]-(dp:PORT {guid:'%(dst_guid)s', port_int:'%(dst_port)s'})" % link
        query += " MERGE (sp)-[:CON]->(c0:Connection)-[:CON]->(dp)"
        query += "  ON MATCH SET c0.seen='%(seen)s'" % link
        query += "  ON CREATE SET c0.created='%(seen)s', c0.seen='%(seen)s', c0.state='LATEST'," % link
        query += "                c0.name='%s'" % name
        if link['src_guid'] > link['dst_guid']:
            query += " MERGE (src)-[:LINKED]->(dest)"
        self._cfg._logger.debug(query)
        self._gdb.query(query, params=link)
        ## If it's an HCA
        name = "SW%s[%s]->%s[%s]" % (
            link['src_guid'][-3:], link['src_port'],
            link['dst_name'].split("_")[0], link['dst_port'],
        )
        query = "MATCH (src)<-[:PART_OF]-(sp:PORT {guid:'%(src_guid)s', port_int:'%(src_port)s'})," % link
        query += " (dest:HCA)<-[:PART_OF]-(dp:PORT {guid:'%(dst_guid)s', port_int:'%(dst_port)s'})" % link
        query += " MERGE (sp)-[:CON]->(c0:Connection)-[:CON]->(dp)"
        query += "  ON MATCH SET c0.seen='%(seen)s'" % link
        query += "  ON CREATE SET c0.created='%(seen)s', c0.seen='%(seen)s', c0.state='LATEST'," % link
        query += "                c0.name='%s'" % name
        self._cfg._logger.debug(query)
        self._gdb.query(query, params=link)

    def get_xmit_ports_for_hca_route(self, guid=None, hcaregex=None):
        """
        :return: List of all routes towards HCA matching guid (if None, all)
        """
        ret = []
        # MATCH (np:PORT)-[NC:CON]->(c:Connection)-[:ROUTE]->(:HCA {guid:'0xf4521403007d4490'}) RETURN *
        query = "MATCH (n)<-[NP:PART_OF]-(np:PORT)-[C:CON]->(c:Connection {state:'LATEST'})-[R:ROUTE]->"
        if guid is None:
            query += "(h:HCA)"
        else:
            query += "(h:HCA {guid:'%s'})" % guid
        if hcaregex is not None:
            query += " WHERE h.name =~ '%s'" % hcaregex
        query += " RETURN n,NP,np,C,c,R,h"
        res = self._gdb.query(query, data_contents=True)
        for row in res.rows:
            xp = XmitPortCnt(sw=row[0], sw_port=row[2], con=row[4], hca=row[6])
            ret.append(xp)
        ## send metrics of ENDPOINTS
        query = "MATCH (sw:SW)<-[SP:PART_OF]-(swp:PORT)<-[SC:CON]-(c:Connection {state:'LATEST'})<-[NC:CON]-(np:PORT)-[:PART_OF]->"
        if guid is None:
            query += "(h:HCA)"
        else:
            query += "(h:HCA {guid:'%s'})" % guid
        if hcaregex is not None:
            query += " WHERE h.name =~ '%s'" % hcaregex
        query += " RETURN sw,SP, swp, SC, c, NC, h"
        res = self._gdb.query(query, data_contents=True)
        for row in res.rows:
            xp = XmitPortCnt(sw=row[0], sw_port=row[2], con=row[4], hca=row[6], end_node=True)
            ret.append(xp)
        return ret

    def merge_route(self, route):
        if route['dst_type'] == "HCA":
            # Since the destination is a HCA, we assume we are originating from an SW
            # -> Hence, ports have the same GUID, the port_int distinguishes
            query = "MATCH (dp:PORT {guid:'%(dst_guid)s'})-[:PART_OF]->(dn:%(dst_type)s)," % route
            query += " (sp:PORT {guid:'%(src_guid)s', port_int:'%(out_port)s'})" % route
            query += " MERGE (sp)-[:ROUTE_TO]->(dn)"
        else:
            # If the destination is a SW, only a SW source is of interest, since the port of an HCA is
            # only connected to one switch its the gateway to every destination
            query = "MATCH (dn:%(dst_type)s {guid:'%(dst_guid)s'})," % route
            query += " (sp:PORT {guid:'%(src_guid)s', port_int:'%(out_port)s'})" % route
            query += " MERGE (sp)-[:ROUTE_TO]->(dn)"
        self._cfg._logger.debug(query)
        self._gdb.query(query, params=route)

    def merge_slurm_partition(self, partition, nodeset):
        """
        :param partition: Name of partition
        :param nodeset: clustershell format of nodenames (e.g. compute[0-6])
        """
        query = "MATCH (n:HCA) WHERE n.name =~ '(%s).*'" % "|".join(NodeSet(nodeset))
        query += " MERGE (p:SlurmPartition {name:'%s'})" % partition
        query += " MERGE (n)-[:MEMBER]->(p)"
        self._gdb.query(query)

    def merge_slurm_job(self, jobinfo):
        """ Puts job information in cluster
        """
        query = "MERGE (j:SlurmJob {id: '%(JobId)s', user:'%(User)s', name:'%(Name)s', batch: '%(BatchFlag)s', command: '%(Command)s'})" % jobinfo
        query += "ON CREATE SET j.created=timestamp(), j.seen='%(seen)s', j.state='%(JobState)s'" % jobinfo
        query += "ON MATCH SET j.seen='%(seen)s', j.started='%(StartTime)s', j.state='%(JobState)s'" % jobinfo
        self._gdb.query(query)
        if jobinfo['NodeList'] is not None:
            query = "MATCH (n:HCA) WHERE n.name =~ '(%s).*'" % "|".join(NodeSet(jobinfo['NodeList']))
            query += " MATCH (j:SlurmJob {id: '%(JobId)s'})" % jobinfo
            query += " MERGE (n)-[:JOBCLIENT]->(j)"
            self._gdb.query(query)
        if jobinfo['JobState'] != "PENDING":
            try:
                query = "MATCH (j:SlurmJob {id: '%(JobId)s'})" % jobinfo
                query += " MATCH (b:HCA) WHERE b.name =~ '%(BatchHost)s.*'" % jobinfo
                query += " MERGE (b)-[:JOBMASTER]-(j)"
            except KeyError:
                print jobinfo
                raise
            self._gdb.query(query)
        if jobinfo['JobState'] in ("COMPLETED", "CANCELLED"):
            query = "MATCH (j:SlurmJob {id: '%(JobId)s'})" % jobinfo
            query += " SET j.state='%(JobState)s', j.end='%(EndTime)s'" % jobinfo
            self._gdb.query(query)

    def mark_unknown_slurm_jobs(self, seen):
        """ Mark disapeart jobs as state=UNKOWN
        """
        query = "MATCH (j:SlurmJob) WHERE (not j.seen='%s') AND j.state IN ['RUNNING', 'PENDING'] SET j.state='UNKOWN'" % int(seen)
        self._gdb.query(query)

    def get_slurm_partitions(self):
        """ get partition information
        """
        query = "MATCH (p:SlurmPartition)<-[:MEMBER]-(h) RETURN p, h"
        res = self._gdb.query(query, data_contents=True)
        for row in res.graph:
            print row

    def get_switches(self):
        """
        :return: list of switches
        """
        query = "MATCH (s:SW) RETURN s"
        res = self._gdb.query(query, data_contents=True)
        ret = []
        for row in res.rows:
            ret.append(row[0])
        return ret

    def get_hcas(self):
        """
        :return: list of hcas
        """
        query = "MATCH (h:HCA) RETURN h"
        res = self._gdb.query(query, data_contents=True)
        ret = []
        for row in res.rows:
            ret.append(row[0])
        return ret

    def merge_ib_routes(self, routes):
        """
        :param routes: List of params
        """
        ## Make sure routing is set
        now = int(time.time())
        md5sum = routes['md5']
        query = "MERGE (r:Routing {md5:'%s'}) ON MATCH SET r.seen='%s', r.state='LATEST'" % (md5sum, now)
        query += " ON CREATE SET r.create='%s', r.seen='%s', r.state='LATEST'" % (now, now)
        self._gdb.query(query)
        query = "MATCH (r:Routing) WHERE not r.seen='%s' SET r.state='OUTDATED', r.outdated='%s'" % (now, now)
        self._gdb.query(query)
        sw_rts = []
        hca_rts = []
        for src_guid, routes in routes['routes'].items():
            for route in routes:
                route['seen'] = now
                if route['dst_type'] == "SW":
                    sw_rts.append(route)
                else:
                    hca_rts.append(route)
        # SW routes
        # TODO: bulk!
        #query = "MATCH (sp:PORT {guid:{src_guid}, port_int:{out_port}})-[:CON]->(dp:PORT {guid:{dst_guid}})-[:PART_OF]->(d:SW {guid:{dst_guid}})"
        #query += " MATCH (r:Routing {state:'LATEST', seen:{seen}})"
        for route in sw_rts:
            query = "MATCH (sp:PORT {guid:'%(src_guid)s', port_int:'%(out_port)s'})-[:CON]->(sc:Connection {state:'LATEST'})" % route
            query += " MATCH (dp:PORT {guid:'%(dst_guid)s'})-[:PART_OF]->(d:SW)" % route
            query += " MATCH (r:Routing {state:'LATEST', seen:'%(seen)s'})" % route
            query += " MERGE (sc)-[:ROUTING]->(r)"
            query += " MERGE (sc)-[:ROUTE]->(d)"
            self._gdb.query(query)
        for route in hca_rts:
            query = "MATCH (sp:PORT {guid:'%(src_guid)s', port_int:'%(out_port)s'})-[:CON]->(sc:Connection {state:'LATEST'})" % route
            query += " MATCH (dp:PORT {guid:'%(dst_guid)s'})-[:PART_OF]->(d:HCA)" % route
            query += " MATCH (r:Routing {state:'LATEST'})" % route
            query += " MERGE (sc)-[:ROUTING]->(r)"
            query += " MERGE (sc)-[:ROUTE]->(d)"
            self._gdb.query(query)

    def get_ib_sw_connections(self):
        """
        :return: List of (sw, swport, remoteport, remote) dicts
        """
        query = "MATCH (sw:SW)<-[PART_OF]-(swp:PORT)-[:CON]-(c:Connection)-[:CON]-(rmp)-[:PART_OF]->(rm) RETURN sw,swp,c,rmp,rm"
        res = self._gdb.query(query, data_contents=True)
        return res.rows

    def unfold(self, res):
        if isinstance(res, QuerySequence) and len(res._elements) >= 2:
            return res[0]
        if isinstance(res, QuerySequence) and len(res) == 1:
            return res[0][0]
        if isinstance(res, list):
            ret = res.pop()
            self.unfold(ret)
        else:
            if isinstance(res, QuerySequence):
                return None
            return res

    def node_by_lid(self, lid):
        """ fetch node using lid
        """
        query = "MATCH (n {lid:'%s'}) RETURN n" % lid
        self._cfg._logger.debug(query)
        res = self._gdb.query(query, returns=(Node))
        node = {}
        if len(res) > 0:
            node['src_node_name'] = res[0][0]['name']
            node['src_lid'] = res[0][0]['lid']
        return node

    def node_by_guid(self, msg):
        """ fetch node using lid
        """
        query = "MATCH (n {guid: '%(src_node_guid)s'}) RETURN n" % msg
        self._cfg._logger.info(query)
        res = self._gdb.query(query, returns=Node)
        node = {}
        if len(res) > 0:
            node['src_node_name'] = res[0][0]['name']
            node['src_lid'] = res[0][0]['lid']
        else:
            return None
        return node

    def get_node_by_port(self, msg):
        """
        :param msg: dict with message information (among them src_port_guid)
        :return: enrichted dict
        """
        ## if it's an HCA port_guid
        try:
            query = "MATCH ()-[:CON]-(p)-[:PART_OF]->(n:HCA {guid: '%(src_port_guid)s'}) RETURN n,p" % msg
        except KeyError:
            pprint(msg)
            raise
        self._cfg._logger.info(query)
        res = self._gdb.query(query, returns=Node)
        node = {}
        if len(res) > 0:
            node['src_type'] = "HCA"
            node['src_node_name'] = res[0][0]['name']
            node['src_lid'] = res[0][0]['lid']
            node['src_port_int'] = res[0][1]['data']['port_int']
        else:
            # must be a switch
            query = "MATCH (s:SW {guid: '%(src_port_guid)s'}) RETURN s" % msg
            self._cfg._logger.info(query)
            res = self._gdb.query(query, returns=Node)
            node['src_type'] = "SW"
            node['src_node_name'] = res[0][0]['name']
            node['src_lid'] = res[0][0]['lid']
            node['src_port_int'] = '0'
        return node

    def get_slurm_jobs(self, state=None):
        """ Fetch slurm jobs
        if state is None, all jobs that were started will be returnd
        """
        if state is None:
            query = "MATCH (j:SlurmJob)<-[jc:JOBCLIENT]-(n) RETURN j,jc,n"
        else:
            query = "MATCH (j:SlurmJob {state:'%s'})<-[jc:JOBCLIENT]-(n) RETURN j,jc,n" % state
        res = self._gdb.query(query, data_contents=True)
        ret = {}
        for row in res.rows:
            job = row[0]
            hca = row[2]
            if job['id'] not in ret.keys():
                ret[job['id']] = SlurmJob(job)
            ret[job['id']].add_node(hca)
        return ret

    def fetch_topology(self):
        """ queries GraphDB to get topology
        """
        query = "MATCH (s)-[L:LINKED]-(d) RETURN s,d"
        res = self._gdb.query(query, data_contents=True)
        topo_cache = set([])
        topo = []
        for row in res.graph:
            src, dest = row['nodes']
            clean_src = {
                'name': src['properties']['name'],
                'guid': src['properties']['guid'],
                'label': ",".join(src['labels'])
                }
            clean_dest = {
                'name': dest['properties']['name'],
                'guid': dest['properties']['guid'],
                'label': ",".join(dest['labels'])
            }
            key = "%s_%s" % tuple(sorted([clean_src['guid'], clean_dest['guid']]))
            if key not in topo_cache:
                topo_cache.add(key)
                topo.append((clean_src, clean_dest))
        return topo